{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import Analisa_Harga_Pangan_Seluruh_Indonesia_2018_2019_Part_1_Data_Analysis as DA_I\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import normaltest\n",
    "from scipy.stats import anderson\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import kruskal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is statistical test for harga pangan in Indonesia 2018 and 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_daerah = ['aceh', 'bali', 'banten', 'bengkulu', 'diy', 'dki_jakarta', 'gorontalo', 'jabar', 'jambi', 'jateng', 'jatim', \n",
    "              'kalbar', 'kalsel', 'kalteng', 'kaltim', 'kalut', 'kepri', 'kepulauan_bangka_belitung', 'lampung', 'maluku',\n",
    "               'malut', 'ntb', 'ntt', 'papua', 'papua_barat', 'riau', 'sulbar', 'sulsel', 'sulteng', 'sultra', 'sulut', \n",
    "               'sumbar', 'sumsel', 'sumut']\n",
    "#year list\n",
    "year = ['2018', '2019']\n",
    "\n",
    "#commodity list\n",
    "commodity_all = ['Bawang Merah', 'Bawang Putih', 'Beras', 'Cabai Merah',\n",
    "       'Cabai Rawit', 'Daging Ayam', 'Daging Sapi', 'Gula Pasir',\n",
    "       'Minyak Goreng', 'Telur Ayam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADHITYAS\\Miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:1673: UserWarning: Input data for shapiro has range zero. The results may not be accurate.\n",
      "  warnings.warn(\"Input data for shapiro has range zero. The results \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bawang Merah': 'Bawang Merah should use Non Parametric testing',\n",
       " 'Bawang Putih': 'Bawang Putih should use Non Parametric testing',\n",
       " 'Beras': 'Beras should use Non Parametric testing',\n",
       " 'Cabai Merah': 'Cabai Merah should use Non Parametric testing',\n",
       " 'Cabai Rawit': 'Cabai Rawit should use Non Parametric testing',\n",
       " 'Daging Ayam': 'Daging Ayam should use Non Parametric testing',\n",
       " 'Daging Sapi': 'Daging Sapi should use Non Parametric testing',\n",
       " 'Gula Pasir': 'Gula Pasir should use Non Parametric testing',\n",
       " 'Minyak Goreng': 'Minyak Goreng should use Non Parametric testing',\n",
       " 'Telur Ayam': 'Telur Ayam should use Non Parametric testing'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normality Test\n",
    "#1. Shapiro-Wilk Test\n",
    "H0 = 'The data is normally distributed'\n",
    "commodities = ['Bawang Merah', 'Bawang Putih', 'Beras', 'Cabai Merah',\n",
    "       'Cabai Rawit', 'Daging Ayam', 'Daging Sapi', 'Gula Pasir',\n",
    "       'Minyak Goreng', 'Telur Ayam']\n",
    "\n",
    "#this function will return dictionaries of each province base on inputted data frame year\n",
    "def shapiro_wilk(data):\n",
    "    results_0 = {}\n",
    "    for x in range(len(list_daerah)):\n",
    "        temp_dict = {}\n",
    "        for i in range(len(commodities)):\n",
    "            stat1, pval1 = shapiro(data[list_daerah[x]][commodities[i]])\n",
    "            temp_dict[commodities[i]] = pval1\n",
    "        results_0[list_daerah[x]] = temp_dict\n",
    "    return results_0\n",
    "\n",
    "#put normality test results inside a dictionary separated by year for each province\n",
    "result_in_each_province = {}\n",
    "for i in range(len(year)):\n",
    "    result_in_each_province[year[i]] = shapiro_wilk(DA_I.all_data_frame_pivot[year[i]])\n",
    "\n",
    "#examine\n",
    "#result_in_each_province['2018']['kalut'] \n",
    "#result_in_each_province['2018']['kalut']['Daging Sapi']\n",
    "#good\n",
    "\n",
    "\n",
    "#this dictionary shows wheter we should use parametric testing or not\n",
    "alpha = 0.05\n",
    "choose_test ={}\n",
    "for a in range(len(list_daerah)):\n",
    "    temp = {}\n",
    "    for b in range(len(commodities)):\n",
    "        if result_in_each_province['2018'][list_daerah[a]][commodities[b]] > 5 and result_in_each_province['2019'][list_daerah[a]][commodities[b]] > 5:\n",
    "            temp[commodities[b]] = commodities[b]+' should use Parametric testing'\n",
    "        else:\n",
    "            temp[commodities[b]] = commodities[b]+' should use Non Parametric testing'\n",
    "    choose_test[list_daerah[a]] = temp\n",
    "\n",
    "#examine\n",
    "choose_test['dki_jakarta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADHITYAS\\Miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2882: RuntimeWarning: invalid value encountered in greater\n",
      "  r_plus = np.sum((d > 0) * r, axis=0)\n",
      "C:\\Users\\ADHITYAS\\Miniconda3\\lib\\site-packages\\scipy\\stats\\morestats.py:2883: RuntimeWarning: invalid value encountered in less\n",
      "  r_minus = np.sum((d < 0) * r, axis=0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bawang Merah': 'Bawang Merah Different distribution (reject H0)',\n",
       " 'Bawang Putih': 'Bawang Putih Different distribution (reject H0)',\n",
       " 'Beras': 'Beras Different distribution (reject H0)',\n",
       " 'Cabai Merah': 'Cabai Merah Same distribution (fail to reject H0)',\n",
       " 'Cabai Rawit': 'Cabai Rawit Same distribution (fail to reject H0)',\n",
       " 'Daging Ayam': 'Daging Ayam Different distribution (reject H0)',\n",
       " 'Daging Sapi': 'Daging Sapi Different distribution (reject H0)',\n",
       " 'Gula Pasir': 'Gula Pasir Same distribution (fail to reject H0)',\n",
       " 'Minyak Goreng': 'Minyak Goreng Different distribution (reject H0)',\n",
       " 'Telur Ayam': 'Telur Ayam Different distribution (reject H0)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hypothesis testing \n",
    "#we will test if there is any significant difference between certain commodity price in the year 2018 and 2019 in the same province\n",
    "H0 = 'The sample distributions are equal'\n",
    "all_hypothesis_test_result = {}\n",
    "for a in range(len(list_daerah)):\n",
    "    temp_1 = {}\n",
    "    for b in range(len(commodity_all)):\n",
    "        #for non parametric testing we use wilcoxon signed rank test\n",
    "        if 'Non Parametric' in choose_test[list_daerah[a]][commodity_all[b]]:\n",
    "            #check each data size\n",
    "            if len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]]) == len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]]):\n",
    "                stat, p = wilcoxon(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]], \n",
    "                                   DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]])\n",
    "                temp_1[commodity_all[b]] = p\n",
    "            elif len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]]) < len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]]):\n",
    "                stat, p = wilcoxon(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]], \n",
    "                                   DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]][0: len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]])])\n",
    "                temp_1[commodity_all[b]] = p\n",
    "            elif len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]]) > len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]]):\n",
    "                stat, p = wilcoxon(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]][0: len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]])], \n",
    "                                   DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]])\n",
    "                temp_1[commodity_all[b]] = p\n",
    "                \n",
    "        else:\n",
    "            #for parametric testing we use 2table t-test \n",
    "            if len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]]) == len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]]):\n",
    "                stat, p = ttest_ind(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]], \n",
    "                                   DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]])\n",
    "                temp_1[commodity_all[b]] = p\n",
    "            elif len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]]) < len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]]):\n",
    "                stat, p = ttest_ind(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]], \n",
    "                                   DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]][0: len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]])])\n",
    "                temp_1[commodity_all[b]] = p\n",
    "            elif len(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]]) > len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]]):\n",
    "                stat, p = ttest_ind(DA_I.all_data_frame_pivot['2018'][list_daerah[a]][commodity_all[b]][0: len(DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]])], \n",
    "                                   DA_I.all_data_frame_pivot['2019'][list_daerah[a]][commodity_all[b]])\n",
    "                temp_1[commodity_all[b]] = p\n",
    "    all_hypothesis_test_result[list_daerah[a]] = temp_1\n",
    "    \n",
    "#examine\n",
    "#all_hypothesis_test_result['jambi']\n",
    "\n",
    "all_hypothesis_test_result_transcribed = {}\n",
    "alpha = 0.05\n",
    "for a in range(len(list_daerah)):\n",
    "    temp_1 = {}\n",
    "    for b in range(len(commodity_all)):\n",
    "        if all_hypothesis_test_result[list_daerah[a]][commodity_all[b]] > alpha:\n",
    "            temp_1[commodity_all[b]] = f'{commodity_all[b]} Same distribution (fail to reject H0)'\n",
    "        else:\n",
    "            temp_1[commodity_all[b]] = f'{commodity_all[b]} Different distribution (reject H0)'\n",
    "    all_hypothesis_test_result_transcribed[list_daerah[a]] = temp_1\n",
    "\n",
    "all_hypothesis_test_result_transcribed['jateng']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bawang Merah': 'Bawang Merah Different distribution (reject H0)',\n",
       " 'Bawang Putih': 'Bawang Putih Different distribution (reject H0)',\n",
       " 'Beras': 'Beras Different distribution (reject H0)',\n",
       " 'Cabai Merah': 'Cabai Merah Different distribution (reject H0)',\n",
       " 'Cabai Rawit': 'Cabai Rawit Different distribution (reject H0)',\n",
       " 'Daging Ayam': 'Daging Ayam Different distribution (reject H0)',\n",
       " 'Daging Sapi': 'Daging Sapi Different distribution (reject H0)',\n",
       " 'Gula Pasir': 'Gula Pasir Different distribution (reject H0)',\n",
       " 'Minyak Goreng': 'Minyak Goreng Different distribution (reject H0)',\n",
       " 'Telur Ayam': 'Telur Ayam Different distribution (reject H0)'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Hypothesis testing 2\n",
    "#we will test if there is any significant difference in certain commodity price from every province\n",
    "#we test 2018 and 2019 separately\n",
    "\n",
    "#2018\n",
    "#since we have 34 province that we want to compare for each commodities, \n",
    "#we have to have all data to be normally distributed, since most of our data doesnt have gaussian distribution,\n",
    "#we are going to use kruskal wallis test for non parametric test, it is equivalent to annova in parametric test\n",
    "list_daerah2 = ['Aceh', 'Bali', 'Banten', 'Bengkulu', 'Daerah Istimewa Yogyakarta', 'DKI Jakarta', 'Gorontalo', 'Jawa Barat', \n",
    "                'Jambi', 'Jawa Tengah', 'Jawa Timur', 'Kalimantan Barat', 'Kalimantan Selatan', 'Kalimantan Tengah', \n",
    "                'Kalimantan Timur', 'Kalimantan Utara', 'Kepulauan Riau', 'Kepulauan Bangka Belitung', 'Lampung', 'Maluku',\n",
    "               'Maluku Utara', 'Nusa Tenggara Barat', 'Nusa Tenggara Timur', 'Papua', 'Papua Barat', 'Riau', \n",
    "                'Sulawesi Barat', 'Sulawesi Selatan', 'Sulawesi Tengah', 'Sulawesi Tenggara', 'Sulawesi Utara', \n",
    "                'Sumatera Barat', 'Sumatera Selatan', 'Sumatera Utara']\n",
    "\n",
    "H0 = 'The sample distributions are equal'\n",
    "kruskal_wallis_results = {}\n",
    "for i in range(len(year)):\n",
    "    temp_0 = {}\n",
    "    for a in range(len(commodity_all)):\n",
    "        stat, p = kruskal(DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[0]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[1]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[2]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[3]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[4]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[5]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[6]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[7]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[8]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[9]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[10]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[11]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[12]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[13]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[14]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[15]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[16]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[17]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[18]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[19]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[20]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[21]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[22]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[23]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[24]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[25]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[26]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[27]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[28]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[29]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[30]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[31]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[32]],\n",
    "                          DA_I.all_data_frame_pivot_commodity[year[i]][commodity_all[a]][list_daerah2[33]],\n",
    "                         )\n",
    "        temp_0[commodity_all[a]] = p\n",
    "    kruskal_wallis_results[year[i]] = temp_0\n",
    "\n",
    "#kruskal_wallis_results['2018']['Bawang Putih']\n",
    "all_kruskal_wallis_test_result_transcribed = {}\n",
    "alpha = 0.05\n",
    "for a in range(len(year)):\n",
    "    temp_1 = {}\n",
    "    for b in range(len(commodity_all)):\n",
    "        if kruskal_wallis_results[year[a]][commodity_all[b]] > alpha:\n",
    "            temp_1[commodity_all[b]] = f'{commodity_all[b]} Same distribution (fail to reject H0)'\n",
    "        else:\n",
    "            temp_1[commodity_all[b]] = f'{commodity_all[b]} Different distribution (reject H0)'\n",
    "    all_kruskal_wallis_test_result_transcribed[year[a]] = temp_1\n",
    "    \n",
    "    \n",
    "all_kruskal_wallis_test_result_transcribed['2018'] \n",
    "all_kruskal_wallis_test_result_transcribed['2019'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i dont have any insight yet, feel free to give me any\n",
    "\n",
    "and if you want to run this script on your local machines, just clone it\n",
    "\n",
    "and send me email if you want all CSV data\n",
    "\n",
    "s.adhitya.dimas@gmail.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
